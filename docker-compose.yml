  services:
    postgres:
      image: postgres:13
      container_name: airflow-postgres
      restart: unless-stopped
      env_file:
        - .env
      environment:
        POSTGRES_DB: ${POSTGRES_DB}
        POSTGRES_USER: ${POSTGRES_USER}
        POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      volumes:
        - postgres-db-volume:/var/lib/postgresql/data

    redis:
      image: redis:latest
      container_name: airflow-redis
      restart: unless-stopped

    init:
      build: .
      container_name: airflow-init
      env_file:
        - .env
      environment:
        AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
        AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${POSTGRES_URI}
        AIRFLOW__WEBSERVER__SECRET_KEY: ${SECRET_KEY}
      volumes:
        - ./dags:${AIRFLOW_HOME}/dags
        - ./dbt:${AIRFLOW_HOME}/dbt
        - ./entrypoint.sh:/entrypoint.sh
      entrypoint: ["/bin/bash", "/entrypoint.sh"]
      depends_on:
        - postgres

    webserver:
      build: .
      container_name: airflow-webserver
      restart: unless-stopped
      env_file:
        - .env
      environment:
        AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
        AIRFLOW__CORE__EXECUTOR: CeleryExecutor
        AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
        AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${POSTGRES_URI}
        AIRFLOW__WEBSERVER__SECRET_KEY: ${SECRET_KEY}
        DBT_PROFILES_DIR: "${AIRFLOW_HOME}/dbt_profiles"
      volumes:
        - ./dags:${AIRFLOW_HOME}/dags
        - ./dbt:${AIRFLOW_HOME}/dbt
      ports:
        - "8080:8080"
      depends_on:
        - postgres
        - redis
      command: webserver

    scheduler:
      build: .
      container_name: airflow-scheduler
      restart: unless-stopped
      env_file:
        - .env
      environment:
        AIRFLOW__CORE__EXECUTOR: LocalExecutor
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${POSTGRES_URI}
        AIRFLOW__WEBSERVER__SECRET_KEY: ${SECRET_KEY}
        DBT_PROFILES_DIR: "${AIRFLOW_HOME}/dbt_profiles"
      volumes:
        - ./dags:${AIRFLOW_HOME}/dags
        - ./dbt:${AIRFLOW_HOME}/dbt
      depends_on:
        - postgres
      command: scheduler

    worker:
      build: .
      container_name: airflow-worker
      restart: unless-stopped
      env_file:
        - .env
      environment:
        AIRFLOW__CORE__EXECUTOR: CeleryExecutor
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${POSTGRES_URI}
        AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
        AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      volumes:
        - ./dags:${AIRFLOW_HOME}/dags
        - ./dbt:${AIRFLOW_HOME}/dbt
      depends_on:
        - postgres
        - redis
      command: celery worker

    flower:
      image: mher/flower:latest
      container_name: airflow-flower
      restart: unless-stopped
      env_file:
        - .env
      environment:
        CELERY_RESULT_BACKEND: redis://redis:6379/0
        CELERY_BROKER_URL: redis://redis:6379/0
      ports:
        - "5555:5555"
      depends_on:
        - redis
        - webserver
      command: celery --app airflow.executors.celery_executor worker --loglevel=info --hostname=airflow@%h

  volumes:
    postgres-db-volume:

